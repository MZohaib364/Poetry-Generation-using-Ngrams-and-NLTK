{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fd097a40",
      "metadata": {
        "id": "fd097a40"
      },
      "source": [
        "\n",
        "  **POETRY GENERATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbfd8420",
      "metadata": {
        "id": "bbfd8420"
      },
      "source": [
        "1 Introduction:\n",
        "In this assignment, you will use n-gram language modeling to generate some poetry using the ngrams. For the purpose of this assignment a poem will consist of three stanzas each containing four verses where each verse consists of 7—10 words. For example, following is a manually generated stanza.\n",
        "\n",
        "دل سے نکال یاس کہ زندہ ہوں میں ابھی،\n",
        "\n",
        "ہوتا ہے کیوں اداس کہ زندہ ہوں میں ابھی،\n",
        "\n",
        "مایوسیوں کی قید سے خود کو نکال کر،\n",
        "\n",
        "آ جاؤ میرے پاس کہ زندہ ہوں میں ابھی،\n",
        "\n",
        "\n",
        "\n",
        "آ کر کبھی تو دید سے سیراب کر مجھے،\n",
        "\n",
        "مرتی نہیں ہے پیاس کہ زندہ ہوں میں ابھی،\n",
        "\n",
        "مہر و وفا خلوص و محبت گداز دل،\n",
        "\n",
        "سب کچھ ہے میرے پاس کہ زندہ ہوں میں ابھی،\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "لوٹیں گے تیرے آتے ہی پھر دن بہار کے،\n",
        "\n",
        "رہتی ہے دل میں آس کہ زندہ ہوں میں،\n",
        "\n",
        "نایا ب شاخ چشم میں کھلتے ہیں اب بھی خواب، سچ ہے ترا\n",
        "\n",
        "قیاس کہ زندہ ہوں میں ابھی\n",
        "\n",
        "The task is to print three such stanzas with an empty line in between. The generation model can be trained on the provided Poetry Corpus containing poems from Faiz, Ghalib and Iqbal.You can scrape other urdu poetry too from internet. You will train unigram and bigram models using this corpus. These models will be used to generate poetry.\n",
        "\n",
        "2 Assignment Task:\n",
        "\n",
        "The task is to generate a poem using different models. We will generate a poem verse by verse until all stanzas have been generated. The poetry generation problem can be solved using the following algorithm:\n",
        "1. Load the Poetry Corpus\n",
        "2. Tokenize the corpus in order to split it into a list of words\n",
        "3. Generate n-gram models\n",
        "4. For each of the stanzas\n",
        "– For each verse\n",
        "* Generate a random number in the range [7...10]\n",
        "* Select first word\n",
        "* Select subsequent words until end of verse\n",
        "* [bonus] If not the first verse, try to rhyme the last word with the last word of the previous verse\n",
        "* Print verse\n",
        "– Print empty line after stanza\n",
        "2.1 Implementation Challenges:\n",
        "\n",
        "Among the challenges of solving this assignment will be selecting subsequent words once we have chosen the first word of the verse. To predict the next word, what we aim to compute is the most probable next word from all the possible next words. In other words, we need to find the set of words that occur most frequently after the already selected word and choose the next word from that set. We can use a Conditional Frequency Distribution (CFD) to figure that out! A CFD tells us: given a condition, what is likelihood of each possible outcome. [bonus] Rhyming the generated verses is also a challenge. You can build your dictionary for rhyming. The Urdu sentence is written from right to left, so makes your n-gram models according to this style.\n",
        "\n",
        "2.2 Standard n-gram Models\n",
        "We can develop our model using the Conditional Frequency Distribution method. First develop a unigram model (Unigram Model), then the bigram model (Bigram Model) and then trigram model. Select the first word of each line randomly from starting words in the vocabulary and then use the bigram model to generate the next word until the verse is complete. Generate the next three lines similarly.\n",
        " Follow the same steps for the trigram model and compare the results of the two n-gram models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb709115",
      "metadata": {
        "id": "bb709115"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2effe45e-260f-4829-862b-e65281d15583",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2effe45e-260f-4829-862b-e65281d15583",
        "outputId": "1d2407fa-f0f4-4f60-8b1c-82e43da2a936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c485c182-8b66-4b7a-9333-c76c76b490ae",
      "metadata": {
        "id": "c485c182-8b66-4b7a-9333-c76c76b490ae"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "corpus_root = '/home/muhammadzohaib/Semester_3/PAI/A4'\n",
        "wordlists = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
        "\n",
        "# file_id = 'ghalib.txt'\n",
        "# raw_text = wordlists.raw(file_id)\n",
        "\n",
        "file_ids = wordlists.fileids()  # Get a list of file IDs in the corpus\n",
        "\n",
        "for file_id in file_ids:\n",
        "    raw_text = wordlists.raw(file_id)\n",
        "    words = word_tokenize(raw_text)\n",
        "\n",
        "unigrams = nltk.ngrams(words, 1)\n",
        "unigramFD = nltk.FreqDist(unigrams)\n",
        "\n",
        "bigrams = nltk.ngrams(words, 2)\n",
        "bigramFD = nltk.FreqDist(bigrams)\n",
        "\n",
        "trigrams = nltk.ngrams(words, 3)\n",
        "trigramFD = nltk.FreqDist(trigrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387e2e48-4322-4f5c-aaf4-600eab6ad65e",
      "metadata": {
        "id": "387e2e48-4322-4f5c-aaf4-600eab6ad65e",
        "outputId": "c8d71d8c-7cef-4464-ae09-6ac2bd4b2df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<ConditionalFreqDist with 1870 conditions>\n"
          ]
        }
      ],
      "source": [
        "# bigrams = nltk.ngrams(words, 2)\n",
        "# cfd1 = nltk.ConditionalFreqDist(bigrams)\n",
        "\n",
        "# print(cfd1)\n",
        "\n",
        "from nltk import ngrams\n",
        "\n",
        "n = 2  # Change this to 1 for unigrams and 3 for trigrams\n",
        "n_grams = list(ngrams(words, n))\n",
        "\n",
        "# Create a conditional frequency distribution for n-grams\n",
        "cfd = nltk.ConditionalFreqDist(n_grams)\n",
        "\n",
        "# Verify the content of the CFD\n",
        "print(cfd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8454ab8a-dbbd-47c6-9e92-4a313abcae9e",
      "metadata": {
        "id": "8454ab8a-dbbd-47c6-9e92-4a313abcae9e",
        "outputId": "f9b518e6-c9d9-4f20-a214-2d233af64041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<ConditionalFreqDist with 1845 conditions>\n",
            "غریب   اگرچہ   مغربیوں   کا   یہ   بات   کہ\n",
            "بن   کے   لیے   تنگ   چیتے   کا   یہ\n",
            "نومیدی   مجھے   نکتۂ   سلمان   خوش   آہنگ   دنیا\n",
            "اور   بھی   ہیں   وہ   خاک   کہ   میں\n",
            "\n",
            "میں   نے   آخر   جو   آوارۂ   جنوں   تھے\n",
            "وہی   رہے   ہیں   وہ   خاک   کہ   میں\n",
            "میں   نے   آخر   جو   آوارۂ   جنوں   تھے\n",
            "کا   یہ   بات   کہ   میں   نے   آخر\n",
            "\n",
            "لولوئے   لالا   اگر   کیفیت   ہے   یا   میرا\n",
            "جہان   مے   خانہ   ہر   کوئی   بادہ   و\n",
            "ہے   یا   میرا   یا   میرا   یا   میرا\n",
            "ازلی   ہے   یا   میرا   یا   میرا   یا\n",
            "\n",
            "آیا   ہے   یا   میرا   یا   میرا   یا\n",
            "پارس   یہ   بات   کہ   میں   نے   آخر\n",
            "اہل   خرد   کا   یہ   بات   کہ   میں\n",
            "ستارے   یہ   بات   کہ   میں   نے   آخر\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import re\n",
        "\n",
        "corpus_root = '/home/muhammadzohaib/Semester_3/PAI/A4'\n",
        "wordlists = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
        "\n",
        "# file_id = 'ghalib.txt'\n",
        "# raw_text = wordlists.raw(file_id)\n",
        "\n",
        "file_ids = wordlists.fileids()  # Get a list of file IDs in the corpus\n",
        "pattern = r'[،؛؟!\"#\\$%&\\'\\(\\)\\*\\+,\\-\\.\\/:؛;<=>?@\\[\\\\\\]^_`{|}~]'\n",
        "\n",
        "for file_id in file_ids:\n",
        "    raw_text = wordlists.raw(file_id)\n",
        "    raw_text = re.sub(pattern, '', raw_text)\n",
        "    words = word_tokenize(raw_text)\n",
        "\n",
        "unigrams = nltk.ngrams(words, 1)\n",
        "unigramFD = nltk.FreqDist(unigrams)\n",
        "\n",
        "bigrams = nltk.ngrams(words, 2)\n",
        "bigramFD = nltk.FreqDist(bigrams)\n",
        "\n",
        "trigrams = nltk.ngrams(words, 3)\n",
        "trigramFD = nltk.FreqDist(trigrams)\n",
        "\n",
        "# bigrams = nltk.ngrams(words, 2)\n",
        "# cfd1 = nltk.ConditionalFreqDist(bigrams)\n",
        "\n",
        "# print(cfd1)\n",
        "\n",
        "from nltk import ngrams\n",
        "\n",
        "n = 2  # Change this to 1 for unigrams and 3 for trigrams\n",
        "n_grams = list(ngrams(words, n))\n",
        "\n",
        "# Create a conditional frequency distribution for n-grams\n",
        "cfd = nltk.ConditionalFreqDist(n_grams)\n",
        "\n",
        "# Verify the content of the CFD\n",
        "print(cfd)\n",
        "\n",
        "import random\n",
        "\n",
        "cfd1 = nltk.ConditionalFreqDist(bigrams)\n",
        "n=2\n",
        "\n",
        "length = random.randint(7,10)\n",
        "\n",
        "for i in range(4):\n",
        "\n",
        "    for j in range(4):\n",
        "\n",
        "        verse = [random.choice(words)]\n",
        "\n",
        "        for k in range(length-1):\n",
        "\n",
        "            context = verse[-1]\n",
        "            # print(context)\n",
        "            next_word = cfd[context].max()\n",
        "            verse.append(' ')\n",
        "            verse.append(next_word)\n",
        "\n",
        "        print(\" \".join(verse))\n",
        "\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}